요약
====================

요약해석을 잘 활용하는 양방향 합성 방법 전체에 대해 말글로 정리한다. 실제 소스의 어디에 구현되어있는지도 함께 달아둔다.

이 중 이 연구에서 특히 중요한 포인트로 생각되는 부분은 아래의 항목이다.

* [싹수 분석](#싹수-분석의-적용과-결과-활용)
   + [크기가 제한된 구체화](#부품의-조건---크기가-제한된-구체화)
* [부품 검색](#부품-검색)

일반
====================

문제의 도메인(BitVec, Bool, ...)과 무관하게 공통적으로 사용되는 로직에 대해 설명한다.

signature
--------------------

우리는 CEGIS iteration을 통해 입출력 쌍을 여러개 얻게 되는데, 각각의 입출력 쌍에서는 입력 변수 값이 정해져있으므로 모든 완성된 식은 완벽히 계산된 상수값을 가질 수 있게 된다. 이 입출력 쌍의 갯수만큼의 길이를 갖는 상수값 벡터를 signature라고 부른다. 예를 들어 3개의 입출력 쌍을 가지고 합성을 시도하고 있다면 signature의 길이는 3이다.

top-down 뼈대
--------------------
[구현: Bidirectional](/lib/synthBidir/bidirectional.ml#L353) 을 topdown 키워드로 검색

주어진 문법을 non-terminal 심볼로부터 출발하여 확장하는 식으로 구멍 뚫린 프로그램을 확보한다.
Start 심볼을 시작점으로 삼아서 적용 가능한 모든 production rule을 한번, 두번, 세번, ... 적용하는 식으로 동작하는데, 문서를 작성중인 현재 시점 기준으로 top-down은 합성 개시 시점에 일정 기준을 충족할 때까지 완료한 후 일단 완성된 뼈대 집합을 합성 과정동안 그대로 고정한다. 초기 top-down을 어디까지 할지는 ```-topdown``` 옵션으로 지정할 수 있다.

* -depth1: 무작정 Start에 production rule을 한 번 적용한다.
* -depth2: 무작정 Start에 production rule을 두 번 적용한다. 즉, 한 번 적용된 뼈대들을 모은 후 그 모든 뼈대의 가장 얕은/맨 왼쪽 non-terminal symbol에 다시 production rule을 적용한다.
* -holeN: 적어도 하나의 뼈대에 빈 칸(non-terminal symbol)이 N개 이상 확보될 때까지 확장 과정을 지속한다. N이 1일땐 잘못된 입력으로 간주한다.
* -topdown 옵션에 아무것도 지정하지 않거나 잘못된 값을 전달할 때 사용되는 기본값은 hole2이다.

이 뼈대에는 기본적으로 ast 상 root node, 즉 계산을 마친 최종 결과의 요약값이 주어진 출력값의 signature를 요약한 값이라는 사실을 함께 매달아둔다. 이를 기반으로 합성 진행중에 생성되는 모든 구멍 있는 프로그램들은 프로그램 포인트 별 요약값 테이블을 항상 함께 달고다닌다.

bottom-up 부품
--------------------

## 부품 저장소
* [구현: Components](/lib/synthBase/components.ml)

bottom-up 방법으로 수집하는 완성된 프로그램 조각(=부품)은 합성 과정에 따라 굉장히 많은 수를 생성할 수 있고(수백만 혹은 수천만 개까지) 순회와 탐색을 여러번 많이 해야하기 때문에 효율을 위해 다소 복잡한 자료구조로 저장하고있다. 

* `min_size`: 보유중인 부품 중 최소 크기. 부품이 하나도 없을땐 0이지만 보통 크기 1부터 만들기 시작하므로 이 값은 거의 항상 1이다.

* `max_size`: 보유중인 부품 중 최대 크기. 만들려고 시도한 부품 최대 크기가 아니라 실제로 부품 풀에 들어있는 부품 중 가장 큰 부품의 크기로 설정된다.

* `nt_sig_to_expr`: 각 non terminal 심볼별로 특정 signature 를 갖는 부품은 최초로 만들어진 하나만 보유하고 나머지는 버린다. 현재 보유중인 입출력 쌍들을 기준으로 signature가 겹치는 부품은 사실상 서로 같은 식이기 때문이다. 부품은 크기가 작은 것부터 만들기 때문에 이렇게 하면 같은 값을 갖는 식 중 가장 작은 부품을 보유할 수 있게 된다. 이 동작을 위해, non terminal |-> signature |-> expr 의 이중맵을 `nt_sig_to_expr`에 저장하고있다. 또한 합성 과정에서 특정 미완성 구멍에서 계산돼야 할 signature가 명확한 경우에 부품 전체를 탐색하는 대신 해당 부품을 즉시 꺼내는 용도로도 사용된다. (`Components.find_expr_of_nt_sig`)

* `nt_sig_search`: nt_sig_to_expr 을 좀더 세분화하여 저장하는 별도의 자료구조인데, 이에 대해서는 아래 다른 항목으로 좀더 자세히 설명하도록 한다. [구현: SigSearch](/lib/synthBase/sigSearch.ml) 특정 구멍에 들어가야하는 signature 중 일부 정보만을 가지고도 그에 맞는 부품 집합을 꺼낼 수 있도록 도와주는 보조 자료구조이다.

* `nt_to_expr_size_ordered`: 각 non terminal 별로 만들어진 부품 전체를 순회하기 좋은 형태로 저장해두는 공간. 부품 뭉치는 `type m_expr_list = expr_set array ref` 으로 정의되어있다. 

expr_set은 부품의 집합을 만들어두되, 집합의 크기 조회와 순회를 효율적으로 하기 위해 cardinal 값과 list 표현을 캐싱해두는 형태이다. 리스트로 바꿔놓고 순회하는 이유는 부품 전체에 대한 순회가 굉장히 자주 일어나는데 TreeSet에 대한 순회는 DFS로 이뤄지기 때문에 연산이 리스트 순회에 비해 복잡하기 때문이다. 리스트는 한 번 만들어두면 tail 포인터로 넘어가기만 하면 되므로 하나의 자료구조를 만들어두고 동시에 여러 개의 enum 이라도 효율적으로 순회를 할 수 있다.

array 의 index로는 부품의 크기를 사용한다. 즉 array의 0번째 칸은 사용하지 않고 1번째 칸은 크기 1인 부품들로만 이루어진 expr_set, 2번째 칸은 크기 2인 부품들로만 이루어진 expr_set을 저장하는 식이다. 합성 과정 특성상 a) 부품 크기는 작은 것부터 점차 증가하고, b) 같은 크기를 갖는 부품을 한 번에 대량으로 생성하며, c) 일단 특정 크기 부품을 다 만들고나면 그 크기의 부품은 더 이상 추가되지 않는다. 이러한 특성을 최대한 활용하기 위해, 크기 N인 부품을 생성하는 동안엔 tree set에 그 크기의 부품들을 하나씩 추가하며 모아두고 생성이 끝나면 한 차례 list로 변환한 다음 이 list를 반복적으로 순회하는 것이다.

또한 이 자료구조를 활용하면 부품의 순회를 자연스럽게 작은 것부터 순차적으로 할 수 있어서 더욱 효율적이다. 부품을 크기별로 미리 분류해두지 않고 뭉뚱그려 모은다면 부품 집합을 만드는 과정에서 부품의 크기도 comparator로 활용해야하는데, 이렇게 하면 어차피 일정한 크기 단위로 부품이 대량 생산되는 특성상 매번 불필요하게 크기를 비교해야하므로 비효율적이다.

## 부품 순회
* [구현: CompEnum](/lib/synthBase/compEnum.ml)

BatEnum 이 요구하는 스펙과 동일한 방식으로, component_pool 을 다양한 방식으로 순회할 수 있도록 만든 모듈이다. 일반적인 BatSet 등을 그대로 사용하지 않고 복잡한 자료구조에 부품을 저장할 뿐 아니라 부품을 좀 더 다양한 방식으로 순회할 수 있도록 확장하기 위해 BatEnum을 그대로 사용하는 대신 직접 작성한 순회 방식을 사용한다.

순회할 부품의 모음 CompEnum.t 를 만드는 방법들은 다음과 같다.

1. `make_ranged`: 순회할 부품의 최소 크기와 최대 크기를 명시하여 그 범위 안에 있는 부품을 작은 것부터 순회한다.

2. `make_full`: make_ranged의 특수한 경우로, 보유한 모든 부품 중 최소 크기에서 최대 크기까지를 순회하도록 하여 보유한 모든 부품을 순회한다.

3. `singleton`: 부품 단 하나를 순회한다. 특정 구멍에 들어갈 부품이 유일하게 정해졌을 때에도 일관적으로 CompEnum을 이용해 로직을 처리하기 위해 존재한다.

4. `from_set`: 주어진 부품 집합을 순회한다.

특정 구멍에 들어갈 수 있는 부품이 [SigSearch](/lib/synthBase/sigSearch.ml)를 통해 일부 부품들로 특정되었을 때 이 부품들만 조립해보기 위해서 사용된다.

5. `clone_ranged`: 이미 부품을 일정량 순회중일 때, 해당 위치부터 또 다른 순회를 시작하고자 할 때 사용된다.

clone을 통한 생성 방법은 교환법칙 성립에 의해 구멍이 대칭인 미완성 프로그램에서 불필요한 중복 생성을 막기 위한 용도로 사용된다. 예를 들어, `bvadd [] []` 와 같은 topdown sketch의 구멍에 10개의 부품을 순차적으로 조립해보는 중이라고 가정해보자. `bvadd compo3 compo5`와 `bvadd compo5 compo3`은 사실상 같은 프로그램이므로 굳이 중복해서 만들어볼 필요가 없다. 이런 중복을 방지하기 위한 한 가지 간단한 방법은 첫 번째 구멍에 넣어보기 위한 부품 순회 상태를 복사하여 그대로 두 번째 구멍을 순회하기 시작하는 것이다. 그럼 구멍1에 부품1을 넣었을 때는 구멍2에 부품1부터 부품10까지를 조립해보고, 구멍1에 부품2를 넣었을 때는 구멍2에 부품2부터 부품10까지를 조립해보는 식으로 대칭으로 인한 중복을 방지하여, 해당되는 케이스에서 조합 횟수를 약 절반으로 줄일 수 있다.

실제 합성
--------------------
* [구현: Bidirectional.synthesis](/lib/synthBidir/bidirectional.ml#L511)

## 큰 흐름

top-level 뼈대 중 하나를 고르고, 그 뼈대의 non-terminal 심볼, 즉 구멍마다 꽂을 수 있는 준비된 부품을 (대체로)작은 것부터 하나씩 끼워넣어 보는 것이 큰 틀이다. 이 과정에서 불필요한 뼈대를 버리고, 구멍에 꽂아볼 가치가 있는(싹수가 있는) 부품이 없는 것으로 판단되는 뼈대도 버리고, 구멍에 모든 부품을 꽂아볼 필요가 없을 때 꽂아봐야하는 부품만 추려서 꽂아보는 것이 탐색 공간의 넓이를 줄이는 데에 필요한 핵심적인 과정이고 여기에 요약 해석 결과를 적극적으로 활용한다.

* [구현: Generator](/lib/synthBase/generator.ml)

만약 뼈대와 부품을 모두 소모했는데 정답을 찾지 못했다면, 부품의 최대 목표 크기를 증가시켜 더 다양한 부품을 확보한 후 뼈대마다 부품 끼워보기를 다시 시작한다. 부품을 키울 땐([Generator.grow](/lib/synthBase/generator.ml#L40)) 목표 크기를 정하고 그 크기의 부품을 새로 만들기 위해 문법의 production rule의 각 non terminal symbol 마다 사용할 수 있는 부품 조합을 지정하고 ([Generator.get_size_partitions](/lib/synthBase/generator.ml#L10)) 그 크기 부품들을 실제로 끼워보며 부품을 만든다. 만들어진 부품은 signature를 계산해보고, 기존 부품과 겹치지 않을 때만 부품 풀에 추가된다.

## 크기 제약

뼈대에 꽂을 부품을 선택활 때는 새로 추가된 부품이 반드시 포함되도록 부품 크기 조합을 제약한다. 예를 들어 크기 1부터 4까지의 부품을 모두 소진했으나 답을 찾지 못하고 크기 5인 부품을 새로 추가했다고 하자. 이 때, 방금 새로 추가한 크기 5인 부품이 하나도 사용되지 않는 조합은 이미 이전에 크기 1부터 4까지의 부품을 보유하고 있을 때 만들어보았을 것이다. 따라서 새로 추가된 부품이 1개 이상 반드시 포함되어야 의미가 있는 조합이 된다. 이런 제약 조건은 [synthesis](/lib/synthBidir/bidirectional.ml#L511) 함수 안의 `main_loop` 함수에 전달되는 `neccessary_compo_size_range` 매개변수를 통해 제어된다.

또한 합성 목표 프로그램의 크기 범위도 제약한다. 크기 8까지의 부품을 이미 확보해둔 상황이라면, 뼈대에 굳이 작은 부품들을 꽂아서 크기 8 이내의 프로그램을 만들어보는 것은 시간 낭비일 것이다. 부품 생산 과정에서 정답이 찾아진다면 즉시 그 회차의 합성을 종료하고 정답을 CEGIS 반복에 전달하기 때문이다. 따라서 뼈대에 부품을 꽂아 만들어보고자 하는 프로그램의 크기는 확보한 부품의 최대 크기보다 1 이상 커야한다. 이런 제약 조건은 [compose_for_sketch](/lib/synthBidir/bidirectional.ml#L119) 함수의 `compose_spec.min_result_size`, `compose_spec.max_result_size` 매개변수를 통헤 제어된다.

위의 두 제약 방식은 부품의 크기와 목표 프로그램의 크기가 커질수록 부품과 대상 프로그램 갯수가 기하급수적으로 증가하므로 전체 합성 효율 향상에 아주 큰 지분을 차지하는 못하지만 탐색 공간을 중복해서 방문하는 것을 어느 정도는 줄여준다.

## 대칭식 처리

교환법칙이 성립하는 연산들이 많이 존재한다. BitVec에서는 add, mul, and, or, xor 이 있고 Bool에서도 and, or, xor이 있다. [`Operators.is_commutative_op`](/lib/synthLang/operators.ml#L162)로 체크한다.
교환법칙이 성립하는 연산이 사용된 뼈대의 양쪽 피연산자가 부품을 끼워넣을 구멍이고 현재 남은 구멍이 그 두개 뿐이라면, 부품 전체를 순회하는 대신 [새로 추가된 부품만을 순회](/lib/synthBidir/bidirectional.ml#L318)한다.
어차피 새로 추가된 부품은 반드시 한번은 사용되어야하므로 대칭인 연산에서는 먼저 사용해도 된다.
아주 많은 경우에 요약값 활용 부품 검색에 의해 나머지 한 칸의 부품이 확실하게 결정되거나 매우 적은 갯수만 남게 되므로, 이 방법으로 첫번째 구멍에서 모든 부품을 굳이 활용하는 것에 효율적으로 탐색 공간을 뒤져볼 수 있다.

예를 들어 사이즈 1인 부품 4개에 대해 한차례 조립 시도를 끝냈고 이번에 사이즈 2인 부품 8개를 새로 추가한 상황에서 add 연산을 조립중이라고 하자.
첫번째 구멍에 사이즈 1인 부품부터 모두 넣어볼 경우 12개의 미완성 프로그램을 생성해야한다.
그런데, add 연산은 완전히 역함수가 존재하는 연산이므로 남은 구멍이 만족해야할 signature가 정확히 계산되기 때문에 두번째 구멍에 대해서는 부품 순회를 하지 않고 검색만 수행한다.
따라서 나머지 구멍에 반드시 사이즈 2인 부품이 들어가야한다는 정보는 그다지 유용하게 활용되지 못한다.
반면에 첫번째 구멍부터 미리 symmetric break을 함께 고려하여 사이즈 2인 필수 부품을 넣어본다면 미완성 프로그램을 8개만 생성하고도 모든 탐색 공간을 모두 확인해보는 효과를 얻을 수 있다.

## 조립 순서

뼈대 하나를 선택한 상황에서 어느 구멍에 먼저 부품을 꽂을지는 뼈대의 모양에 따라 달라진다. 기본적으로는 왼쪽부터, DFS 순서대로 부품을 꽂지만 구멍이 있는 부분식에 사용된 함수의 특성에 따라서 다른 순서를 적용하기도 한다. 순서 선택은 [get_holes_for_compose](/lib/synthBidir/bidirectional.ml#L26) 함수로 결정하는데, 미완성 프로그램에 존재하는 구멍들을 모두 찾아주되 순서를 정해서 알려주는 함수이다. 이때 순서는 우선 순위 높은 구멍과 우선순위 낮은 구멍으로 나눠서 알려준다. 순서를 정하는 목적은 싹수 분석이 효과적으로 작동할 수 있는 모양을 빠르게 제공하는 것이다.

* `BV_AND`, `BV_OR`: 아주 일부의 정보로도 여러 비트의 값을 확정지을 수 있어서 싹수 없는 프로그램을 빨리 판정할 수 있을 가능성이 높으므로, 오른쪽 부분식의 우선순위 높은 구멍만 먼저 채우고 나머지는 후순위로 돌린다. 오른쪽을 먼저 선택하는 이유는 top-down 확장을 왼쪽 우선으로 하기 때문에 오른쪽 부분식의 깊이가 얕을 가능성이 높기 때문이다.

* `BV_XOR`: 좌우의 우선순위 높은 구멍부터 우선 채우고 나서 일부 정보를 획득하면, 그 정보를 활용해 싹수 유무를 판단할 수 있을 가능성이 있어서 우선순위 높은 구멍부터 선택하고 나머지를 후순위로 돌린다.

* `BV_ADD`, `BV_SUB`: 어느 한쪽을 완벽하게 채우고나면 반대쪽 부분식에 대한 작은 문제로 환원할 수 있으므로 한쪽 구멍을 먼저 채워야할 것 같은데, `BV_XOR`과 같은 순서를 선택하고 있다. 실수인지 확인 필요.

* `BV_MUL`, `BV_*SH*`, `BV_*DIV`: 곱셈은 어느 한 쪽을 완벽하게 채우는 것이 역함수를 계산해낼 수 있을 가능성이 생겨서 유리하다. shift 연산은 옮길 거리를 정확히 알면 불가능한 프로그램들을 굉장히 많이 쳐낼 수 있게 되어서 유리하다. 나눗셈은 나누는 값을 정확히 알아야 나눠지는 값에 대한 정보를 역으로 추론할 수 있는 반면, 나눠지는 값에 대한 정보를 미리 아는 것은 큰 도움이 되지 않는다. 이와 같은 이유로 이 연산들은 오른쪽 구멍부터 가득 채운다.

* `BV_*REM`: 나머지 연산에서는 첫번째 피연산자의 값을 정확히 알면 결과값과 조합하여 말이 되는 값과 안 되는 값을 좀 더 걸러낼 수 있을 여지가 생기기 때문에 다른 연산들과 달리 왼쪽 구멍부터 가득 채운다.

## 싹수 분석의 적용과 결과 활용

싹수 분석은 어떤 구멍이 있는 프로그램이 생성될 때마다 매번 작동한다. 구체적으로 분석을 어떻게 하고 분석 결과를 어떻게 저장하고 재사용 하는지는 [분석 설명 문서](/doc/informal_techmemo/abstsem.kor.md)에 따로 정리하기로 하고, 여기서는 임의의 구멍 있는 프로그램을 블랙박스에 던지면 요약 해석 결과를 알려주는 것으로만 생각한다. 블랙박스 내에서 요약값 계산 도중 bottom이 발생하면 즉시 싹수 없는 프로그램([`Infeasible`](/lib/analyzer/transfer.ml#L126))으로 판정된다. 구멍이 없는 프로그램은 완성된 프로그램이므로 분석을 수행하지 않고 식을 직접 계산해서 정답 여부만 판정한다. 싹수 있는 미완성 프로그램에 대해서는 프로그램의 각 부분식마다 계산된 요약값을 매달아서 알려준다.([`NeedMoreAnalysis of AbstState.t`](/lib/analyzer/transfer.ml#L126))

싹수 없는 미완성 프로그램은 더이상의 조립을 중지하고 다음 미완성 프로그램으로 넘어간다. 구멍이 없는 프로그램은 정답 여부를 체크하고 정답이 아니라면 다음 프로그램으로 넘어간다. 싹수 있는 미완성 프로그램은 남은 구멍에 추가로 부품을 꽂아볼 준비를 해야하는데, 이 과정에서도 아직 싹수 분석 결과는 활용된다.

### 부품의 조건 - 크기가 제한된 구체화 

싹수 분석의 결과에서 다음 채워봐야할 구멍(non terminal symbol)에 부품을 채웠을때 반드시 만족해야만 하는 기대되는 요약값(post-condition)을 알 수 있는데, 이 조건을 이용해 구멍에 준비된 부품 전체를 꽂아보는 대신 일부 부품만 꽂아보거나 아무 부품도 꽂아보지 않을 수 있다. 현재 여기에 사용되는 방법은, 구멍에 기대되는 요약값을 적절히 구체화(concretize)하여 그 결과를 활용하는 것이다. 물론 임의의 요약 도메인에 존재하는 모든 요약값에 대해 항상 구체화 시킨 결과를 유한 시간 내에 계산해낼 수 있는 것은 아니다. 제대로 디자인 된 요약 해석이라면 구체화 함수(gamma function)은 수학적으로는 모든 요약 도메인 값에 대해 정의되어있지만 그 결과가 무한 집합일 수도 있기 때문에 무작정 구체화를 시도하면 계산이 끝나지 않을 수도 있다.

여기서 주요 착안점은 첫째, 요약 도메인의 모든 값에 구체화 함수를 적용한 집합을 항상 효율적으로 계산해낼 수 있는 것은 아니지만, 구체화 함수를 적용한 결과 집합의 크기가 일정 이내일지 사전에 '간을 보고' 할 만할 때만 계산을 시도하는 것은 충분히 가능하다는 점이다. 예를 들어 구체화 함수를 적용해보기 전에 구체화 시킨 집합의 크기가 8 이내일 때만 구체화 결과를 활용하기로 하는 것은 충분히 가능하다. 아주 쉬운 방법으로는 일단 구체화를 진행해보고 집합의 크기가 8을 넘어갈 때 포기하는 방법도 있다. 만약 어떤 요약 도메인 값을 구체화 시킨 집합의 크기가 1이라면 그 구멍에 들어올 값의 조건은 특정한 상수로 확정된다.

둘째, 우리가 미완성 프로그램을 분석하고 있지만 양방향 합성이 진행되면서 구멍을 더 많은 구멍으로 확장시키는 것이 아니라 구멍에 완성된 프로그램(-정확한 값이 계산되는-)을 꽂기 때문에, 남은 구멍에 들어갈 수 있는 값의 조건 아예 상수로 결정되거나 매우 폭좁은 값이 되는 경우도 많다는 점이다. 예를 들어 미완성 프로그램 `bvadd [hole1] [hole2]` 의 hole2에 20을 꽂았을 때 결과값이 30이라는 사실을 알고있다면 복잡한 요약 해석 없이도 직관적으로 hole1에 들어올 프로그램은 반드시 10이라는 상수값으로 계산되어야한다는 사실을 알 수 있다. 물론 `bvadd` 연산은 역원을 이용해 반대쪽 값을 쉽게 계산할 수 있는 특수한 연산이고 모든 미완성 프로그램이 이렇게 간단한 것만은 아니므로 프로그램의 형태에 따라서 요약 해석이 동원될 필요가 있다. 하지만 포인트는 미완성 프로그램의 상당 부분이 이미 계산된 값일 수 있고 요약 해석을 충분히 정교하게 수행하면 빈칸의 조건을 꽤 폭좁게 추론해낼 수 있다는 점, 그리고 그 조건을 이용해 빈칸에 와야할 값을 추려낼 수 있다는 점이다.

셋째, 우리는 입출력 쌍이 쌓여갈 때 각 입출력 쌍마다 계산되는 값을 따로따로 signature라는 형태로 보존하므로 어느 입출력 쌍을 사용했느냐에 따라 구체화된 집합의 크기가 달라질 수 있다는 점이다. 예를 들어 어떤 프로그램의 입출력 쌍이
```
f(0) = 0
f(1) = 1
```
로 주어졌을 때, `bvand [hole1] x` 이라는 미완성 프로그램이 선택되었다면
```
bvand [hole1] 0 = 0
bvand [hole1] 1 = 1
```
이라는 사실을 알 수 있는데, 이때 `[hole1]`에 와야할 부품의 가장 낮은 자리 비트는 첫번째 입출력 쌍에서는 0과 1 모두 올 수 있어서 정보를 알 수 없지만 두번째 입출력 쌍에서는 반드시 1이어야한다는 점을 알 수 있다. 이렇게 입출력 쌍에 따라 정보의 양이 다를때, 더 많은 정보를 제공하는 입출력 쌍에서 부품의 조건을 제약하는 것만으로도 유의미하게 탐색 공간을 줄일 수 있다.

### 부품의 조건 적용 - 적은 부품 순회하기, 현재 부품 풀로는 싹수 없음

위와 같이 크기가 제한된 구체화 결과를 사용해서 그에 맞는 부품들을 추려낼 방법이 있다면 우리는 보유한 수많은 부품들을 모두 사용해보는 대신 꼭 필요한 부품만 사용할 수 있다.

예를 들어 5개의 입출력 쌍을 보유한 상황에서 특정 구멍에 올 부품의 조건 요약값을 구체화해본 결과, 0번째 입출력 쌍에서는 15 혹은 35, 3번째 입출력 쌍에서는 7, 8, 9 중 하나가 와야한다는 사실을 알 수 있었고 나머지 입출력 쌍에서는 정보를 얻지 못했다고 하자. 그렇다면 우리는 전체 부품 중에서 아래의 signature를 갖는 부품들만 확인해보면 된다.
```
[15, *, *, 7, *]
[35, *, *, 7, *]
[15, *, *, 8, *]
[35, *, *, 8, *]
[15, *, *, 9, *]
[35, *, *, 9, *]
```
물론 구체화 시도 크기가 p, 입출력 쌍의 갯수가 N개일 때 조회해봐야 할 signature 쌍의 수는 최대 p^N 개까지 늘어날 수 있다. p=4, 입출력 쌍이 8개라면 65536개의 signature를 확인해봐야하는 것이다. 그러나 실제 적용 과정에서는 많은 signature를 확인하는 비용보다 부품 전체를 순회하는 비용이 더욱 크다. 비교적 어렵고 규모가 큰 문제에서는 부품 크기가 100만개를 우습게 넘어가는데, 이것을 보두 순회하는 것보다는 수만 개의 signature를 확인해보는 것의 비용이 더 적다. 그 뿐 아니라, 예를 들어 위의 과정에서 우리가 보유한 부품 중 그 어떤 부품도 0번째 값으로 15를 갖지 않고, 3번째 값으로 7과 8을 갖지 않는다면 검색 과정에서 위의 signature 전체를 확인하는 대신 `[35, *, *, 9, *]` 한 쌍만 조회해도 충분하며, 이렇게 부품 순회를 줄이는 일은 실험적으로 충분히 많이 일어나는 것이 확인된다. 구체적으로 이 검색을 위해 어떤 자료구조를 준비해두고 어떻게 검색을 수행하는 지는 아래의 [부품 검색](#부품-검색) 항목에서 확인할 수 있다.

이렇게 부품을 조회 결과 꺼내온 부품의 수가 전체 부품보다 충분히 적다면 적은 부품만 순회하여 순회를 금방 끝낼 수 있고, 부품의 집합이 공집합이라면 '현재 부품 풀로는 싹수 없음'이라는 판단을 내릴 수 있어서 bottom 요약값이 발생한 것과 유사한 탐색 공간 쳐내기  효과를 누릴 수 있다.

## 부품 검색

* [구현: SigSearch](/lib/synthBase/sigSearch.ml)

조건에 맞는 부품을 빠르게 찾아내기 위해 부품을 별도의 기준에 따라 갈무리해두는 모듈. 위의 다른 부분들은 단순히 오직 구현 수준에서만 최적화가 적용되었다면 이 모듈은 요약 해석 결과와 직접적으로 관련되는 모듈이므로 이 연구에서 꽤 핵심적인 부분을 차지한다.

이 모듈의 핵심 목표는 부품의 사전 계산된 signature(const list) 의 특정 인덱스에 특정 값이 담겨있는 부품들을 효율적으로 찾아 꺼내오는 것이다. 예를 들어, CEGIS 반복을 통해 입출력 쌍이 5개 확보된 상황을 가정해보자. 이때 어떤 미완성 프로그램의 특정 구멍에 들어가야 햘 부품의 signature에서 0번째에서 4번째까지의 값 중 어떤 방법을 통해 1번째 값은 15, 4번째 값은 71이라는 사실을 알게 되었다면, 우리는 보유하고있는 모든 부품 중 signature의 1번째 값이 15, 4번째 값이 71인 부품들만 뽑아내서 이 부품들만을 구멍에 꽂아보면 된다. 이런 역할을 하는 함수는 `SigSearch.find` 함수이다.

### 일반적인 부품 저장 및 검색 방법

Bool 값을 갖는 부품을 제외하면, 일반적으로 아래와 같은 직관적인 중첩 맵 구조(실제 구현은 배열 - 배열- 맵)로 저장한다.

```
부품 크기(배열) |-> 입출력 인덱스(배열) |-> 상수값(맵) |-> 부품 집합
```

즉, 부품 크기가 3이고 1번째 입출력 인덱스에 해당하는 상수값이 15인 부품들의 집합은 아래의 영역에 모이는 것이다.

```
t.(3).(1).(15)
```

전체적으로 맵이 아닌 배열을 쓰는 이유는 다음과 같다.

부품의 크기는 합성 방식상 가장 작은 1부터 차근차근 늘어나므로 배열을 사용하기에 적합하다. 입출력 인덱스 역시 CEGIS 반복을 돌며 0부터 1씩 늘어나므로 배열을 사용하기에 적합하다. 상수값은 임의의 공간에 분포해있으므로 맵을 사용해야한다.

여기서도 부품을 크기별로 분류해두는 이유는 우리가 실제 합성을 진행할 때 목표 프로그램의 크기에 따라 원하는 부품 크기를 지정한 상태로 부품을 순회하기 때문이다.

이때, 위의 예시와 같이 크기가 `3`인 부품들 중 signature의 `1`번째 값은 `15`, `4`번째 값은 `71`인 부품들은 아래와 같이 추출할 수 있다.

```t.(3).(1).(15) intersect t.(3).(4).(71)```

이 결과가 empty set 이라면, 우리는 현재 합성 시도중인 미완성 프로그램이 `'현재 보유한 부품 풀의 한도 안에서는 싹수가 없다'`라는 판단을 내릴 수 있고 더이상의 합성을 시도하지 않고 다음 미완성 프로그램으로 넘어갈 수 있다.

이 결과 집합이 empty set은 아니라도 충분히 작다면, 예를 들어 100만개의 부품 중 오직 3개만이 이 집합에 들어있다면 우리는 10만번의 순회 대신 3번의 순회만으로 조건에 맞을 가능성이 있는 프로그램 공간을 탐색할 수 있다. 이 효과는 우리가 채우고 있는 구멍이 이 미완성 프로그램의 마지막 구멍일 때도 충분히 크지만, 두 개 이상의 구멍이 아직 남아있을 때는 더욱 크다. 앞서의 부품 100만개 중 3개만 싹수가 있는 상황이 두 구멍 중 첫 번째 구멍에서 발생했다면 우리는 단순히 10만개 중 99997개를 버리는 것이 아니라, 다음 구멍에 10만개의 부품을 다시 꽂아보며 완성 프로그램들을 만들어보지 않아도 되는 효과를 얻을 수 있다. 즉 단순히 계산했을 때 완성 프로그램을 100억개 중 30만개만 만들어봐도 된다는 의미이다.

### Bool 값을 갖는 부품 저장 및 검색 방법

위의 일반적인 구현을 이용해 Circuit 문제를 풀다보니(물론 이 구현으로도 상당히 빠른 시간 안에 답을 찾았지만) 비효율적으로 보이는 부분을 발견하였다. Bool 값에는 true와 false밖에 존재하지 않기 때문에, 위와 같이 N번째 인덱스의 값이 true인 부품 집합, false인 부품 집합을 단순무식하게 수집하면 평균적으로 모든 인덱스의 각 true, false에 전체 부품 집합의 대략 절반이 모이게 된다. 즉 아래와 같은 형태가 될 것이다.
```
cardinal of all compoents set = 1,000,000

index 0 false |-> {500,000 components}
        true  |-> {500,000 components}
index 1 false |-> {300,000 components}
        true  |-> {700,000 components}
index 1 false |-> {800,000 components}
        true  |-> {200,000 components}
index 2 false |-> {400,000 components}
        true  |-> {600,000 components}
...
```

물론 우리가 어떤 훌륭한 분석을 통해 충분히 많은 index의 값들을 true 혹은 false로 특정할 수 있다면 이 집합들을 교집합으로 엮는 과정에서 결과적으로 뽑아내는 부품 집합의 크기는 충분히 많이 줄어들 수 있을 것이다. 그러나 어쨌든 평균적으로 전체 부품 집합의 약 절반 크기에 대해 교집합 연산을 반복하는 것은 굉장히 비효율적일 수 있다.

위의 부품 탐색 과정을 좀 더 최적화하기 위해, Bool 값을 갖는 부품의 signature는 사실상 비트 벡터에 가깝다는 점에 착안하여 아래와 같은 최적화 된 자료구조를 구현하였다.

* Bool 값 부품 검색 자료구조 예시

현재 수집한 입출력 쌍이 총 21개인 상황을 가정한다. signature의 길이는 21이고, 어떤 bool 값을 갖는 부품 하나의 signature는 길이 21인 비트벡터로 표현할 수 있다.

만들어진 부품은 아래와 같이 갈무리된다. 이때도 물론 부품을 크기가 같은 것끼리만 모아서 저장하므로, 아래 제시되는 하나의 `bool_table` 안에서 모든 부품의 크기는 동일하다.

```
bool_table[byte_index] (length = 3 <- 21개의 비트 표현에 3바이트가 필요하므로)
    0 |->
        true_subsigs[bit_index] (length = 8)
            0 |-> {*******1} // 0번째 비트가 1인 byte들의 집합 (길이 255인 bitset으로 표현)
            1 |-> {******1*} // 1번째 비트가 1인 byte들의 집합 (길이 255인 bitset으로 표현)
            ...
            7 |-> {1*******} // 7번째 비트가 1인 byte들의 집합
        false_subsigs[bit_index] (length = 8)
            0 |-> {*******0} // 0번째 비트가 0인 byte들의 집합 (길이 255인 bitset으로 표현)
            1 |-> {******0*} // 1번째 비트가 0인 byte들의 집합 (길이 255인 bitset으로 표현)
            ...
            7 |-> {0*******} // 7번째 비트가 0인 byte들의 집합
        subsig_expr_set[subsig] (length = 255 <- 바이트를 넣으면 즉시 집합이 나오도록)
            0 |-> {signature[7..0] 이 false, false, ..., false 인 모든 부품의 집합}
            1 |-> {signature[7..0] 이 false, false, ..., false, true 인 모든 부품의 집합}
            ...
            255 |-> {signature[7..0] 이 true, true, ..., true인 모든 부품의 집합}
    1 |->
        true_subsigs[bit_index] (length = 8)
            N |-> {N번째 비트가 1인 byte들의 집합}
            ...
        false_subsigs[bit_index] (length = 8)
            N |-> {N번째 비트가 0인 byte들의 집합}
            ...
        subsig_expr_set[subsig] (length = 255)
            0 |-> {signature[15..8] 이 false, false, ..., false 인 모든 부품의 집합}
            1 |-> {signature[15..8] 이 false, false, ..., false, true 인 모든 부품의 집합}
            ...
            255 |-> {signature[15..8] 이 true, true, ..., true인 모든 부품의 집합}
    2 |-> ...
```

이 때 부품을 추가할 때와 검색할 때 일어나는 일은 다음과 같다.

추가하려는 어떤 새 부품 e의 signature가 10101_11100001_00000001 이라면(8비트 단위로 끊어 해석):

맨뒤의 0번째 00000001 부분에 의해 아래의 내용이 추가된다.
```
bool_table.(0).true_subsigs.(0) += 1 // 0번째 비트가 true
bool_table.(0).false_subsigs.(1) += 1 // 1번째 비트가 false
...
bool_table.(0).false_subsigs.(7) += 1 // 7번째 비트가 false

bool_table.(0).subsig_expr_set.(1) += e // 8개의 비트로 표현된 바이트 값이 1인 부품에 e 추가
```

뒤에서 1번째 11100001 부분에 의해 아래의 내용이 추가된다.
```
bool_table.(1).true_subsigs.(0) += 225 // 이진수로 표현된 byte 11100001 의 값 225에서 0번째 비트가 1
bool_table.(1).false_subsigs.(1) += 225 // 225에서 1번째 비트가 0
...
bool_table.(1).true_subsigs.(7) += 225 // 225에서 7번째 비트가 1

bool_table.(0).subsig_expr_set.(255) += e // 8개의 비트로 표현된 바이트 값이 225인 부품에 e 추가
```

마지막으로 뒤에서 2번째 10101 부분에 의해 아래의 내용이 추가된다.

```
bool_table.(2).true_subsigs.(0) += 9 // 이진수로 표현된 byte 10101 의 값 5에서 0번째 비트가 1
bool_table.(2).false_subsigs.(1) += 9 // 5의 1번째 비트가 0
bool_table.(2).true_subsigs.(2) += 9 // 5의 1번째 비트가 1
bool_table.(2).false_subsigs.(3) += 9 // 5의 1번째 비트가 0
bool_table.(2).true_subsigs.(4) += 9 // 5의 1번째 비트가 1

bool_table.(2).subsig_expr_set.(9) += e // 8개(최상위 바이트라 짤려서 5개) 비트로 표현된 바이트 값이 5인 부품에 e 추가
```

이렇게 만든 자료구조를 검색하는 방법은 어렵지 않다.

1번째 값이 false, 4번째 값이 false, 8번째 값이 true인 부품을 찾고 싶다면 아래와 같이 검색한다.

먼저 주어진 인덱스와 값을 같은 byte 영역에 들어가는 것끼리 분류한다. 인덱스 1과 인덱스 4는 공통적으로 0에서 7 사이에 있으므로 0번째 바이트에 배치, 인덱스 8은 8과 15 사이에 있으므로 1번째 바이트에 배치한다.

[(1,false); (4,false)] 를 이용해 0번째 바이트 정보에 매칭되는 부품 집합을 구한다. 1번째 값이 false인 0번째 바이트는 `******0*` 형태이므로 `bool_table.(0).false_subsigs.(1)` 에 모두 들어있다. 4번째 값이 false인 0번째 바이트 역시 `***0****` 형태이므로 `bool_table.(0).false_subsigs.(4)` 에 모두 들어있다. 이 둘의 교집합을 구하면 `***0**0*` 형태로 0번째 바이트와 4번째 바이트가 false인 모든 바이트를 얻을 수 있다.
이러한 모든 바이트는 최대 64개 존재할 수 있을 것인데(8개의 비트 둥 2개가 특정되어 2^6=64개), 실제 생성된 부품이 64가지 경우의 수를 모두 충족시키지 못할 수도 있으므로 64개 이하로 3개, 62개, 0개 등 어떤 갯수로든 존재할 수 있다. 위의 true_subsigs와 false_subsigs 집합에는 실제로 생성해서 추가한 부품의 signature 에서 추출해낸 바이트만 들어있기 때문이다.

이렇게 어떤 바이트의 집합을 만들어냈고 이것이 empty set 이라면 해당되는 부품은 없는 것이다. 이 바이트의 집합이 empty set이 아니라면 1번째와 4번째 값이 false라는 조건을 만족하는 부품이 반드시 1개 이상 존재한다는 의미이다. 바이트 집합에 담긴 바이트들을 모두 순회하며 `bool_table.subsig_expr_set.(byte)` 형태로 접근하여 부품들을 꺼낸 후 이 집합을 모두 union 하면 1번째와 4번째 값이 false인 모든 부품의 집합을 구할 수 있다.

같은 작업을 1번째, 2번재, ... 바이트들에 대해 똑같이 진행한다. 현재 예시에서는 8번째 값이 true인 집합을 원하므로 \[(8,true)\]를 이용해 2번째 바이트 정보에[ 매칭되는 부품 집합을 구한다. `bool_table.(1).true_subsigs.(0)` 에 담긴 바이트들을 대상으로 `bool_table.(1).subsig_expr_set.(byte)` 형태로 접근하여 부품 집합을 얻으면 8번째 값이 true인 모든 부품의 집합을 구할 수 있다.

이렇게 바이트 단위로 조건을 만족하는 부품의 집합을 구한 후, 이 집합들을 다시 교집합 연산하면 우리가 원하는 조건을 만족하는 부품들만을 뽑아낼 수 있다.

* 효율

성능은 실험적으로 확인되었지만, 위의 자료구조를 통해 대략적으로 아래와 같은 효율 개선이 기대된다.

기존의 경우 시그니처 길이가 21, 부품 갯수가 100만개라면 100만개의 집합을 2개로 쪼갠 각 집합이 총 21개 존재하게 되어 모든 집합의 원소가 중복을 포함하면 약 2100만개가 된다. 그러나 새 방법은 시그니처 길이가 21일때 바이트로는 3바이트가 되므로 중복을 포함한 모든 원수의 갯수는 대략 3개 바이트영역 * 각 100만개 = 300만개가 되어 최대 1/8 수준으로 줄어든다. 이 때 부품 집합 외에 검색에 필요한 부가적인 자료구조는 각 바이트 자리마다 다음과 같다. 8개의 각 비트 자리마다 그 비트가 0인 바이트들과 1인 바이트들을 수집하는 공간에는 각각 길이가 256인 32바이트 비트셋을 8 * 2 = 16개 저장해야하므로 약 512바이트, 바이트를 이용해 각 부품 집합에 바로 접근하기 위해 길이 256인 배열에 집합들을 배분해 넣으므로 256 word = 64비트 환경 기준 16KB 으로 대략 시그니처 길이 8비트 당 17KB 정도를 소모한다. 입출력 쌍이 약 100개까지 쌓이더라도 300KB가 채 안 되는 추가 메모리로 부품 집합을 중복이 더 적게 더 효율적으로 배분해 저장하는 것이다. 총 부품의 수가 커질수록 이 효과는 극대화된다.

탐색 과정의 효율도 개선된다. 나이브한 구현에서는 부품의 갯수가 100만개라면 각 비트 자리별 값을 검색했을때 해당되는 부품 집합은 평균적으로 50만개이다. 따라서 시그니처 길이 21개 중 1/3인 7개의 비트의 값을 정확히 알고있다고 가정하면 평균 50만개인 집합의 교집합 연산을 7회 수행해야한다. 반면에 새 방법으로는 7개의 비트가 적절히 3개의 바이트 영역에 각기 1개, 3개, 3개로 쪼개져 담겨있다고 가정했을 때 높은 자리 바이트 영역에서는 어쩔 수 없이 기존과 같이 평균 50만개짜리 부품 집합을 다뤄야하지만 나머지 두 바이트 영역에서는 비트 3개가 이미 확정되어있어 평균적으로 50만개의 1/4인 12.5만개의 부품 집합만 다루면 된다. 즉, 평균 50만개의 부품 집합을 7개 교집합 연산하는 대신 평균 50만개 * 12.5만개 * 12.5만개 부품 집합으로 총 3개만 교집합 하면 된다. 이때 각 비트 별로 해당되는 바이트 집합은 비트셋을 이용해 저장되어 있으므로 이것을 꺼내 조합하는 연산은 거의 상수 시간에 가깝다. 이런 형태로 부품 갯수가 많아질수록 새 자료구조의 검색 효율은 극대화된다. 더 작은 크기의 집합을 더 적은 갯수 모아두고 교집합 연산을 수행하기 때문에 비용이 이중으로 절감되기 때문이다.

실험에서도 간단한 문제를 풀 때는 시간의 차이가 크지 않지만, 어렵고 복잡한 문제를 풀려고 시도할수록 합성 시간 효율의 개선이 더욱 컸다. 예를 들어 sygus 2018 benchmark의 circiut 문제들 중 이 자료구조를 적용하기 이전에 5초에서 10초의 시간이 걸리던 문제들은 합성 시간이 약 `30~40%`로 줄어들어 2~3초가 된 반면, 10초 이상이 걸린 문제들을 살펴보면 17.3초가 걸리던 CrCy_2-P6_2-P6 문제는 3.27초로 줄어서 `18.9%`, 27.26초가 걸리던 hd09.eqn_sygus_iter_28_1 문제는 5.73로 줄어서 `21.0%`, 46.83초가 걸리던 sorting_naive-opt.eqn_sygus_iter_306_0 문제는 10.95로 줄어서 `23.4%`로 합성 소요 시간을 줄일 수 있었다. 메모리 사용량 개선 효과까지 감안하면 어렵고 복잡한 문제를 풀 수록 위와 같은 최적화는 필수적일 것으로 생각된다.


추가 아이디어 (미구현)
====================


적응형 조립 순서
--------------------
현재 조립의 구멍 순서는 operator만 보고 정한다. (대부분 오른쪽, rem은 왼쪽...)
그런데 현재 partial program과 backward 계산된 sem을 참조해, component 갯수를 먼저 추정해보고 적게 나올 구멍을 먼저 채워보는 것이 유리할 수 있다.
gamma_size_constraint의 결과 품질을 기준으로 정하기 -> 혹은 좀더 비싸게 실제 component 갯수를 세보기 등 적용 가능.


부품 시그니처 기반 구체화
--------------------
현재 크기가 제약된 구체화는 부품과 상관없이 요약 도메인만 바라본 채로 이루어진다.
그러나 우리가 구체화를 하는 이유는 계산되어있는 시그니처와 매칭하여 맞는 부품을 찾기 위한 것이므로 더 효과적으로 해낼 여지가 있을 수 있다.

이제 문제 정의를 요약 도메인 값을 제약 조건 하에 구체화하는 문제가 아니라, 부품 셋에서 요약 도메인을 만족하는 부품을 찾는 문제로 더 일반화한다.
기존에는 이러한 방법 중 하나로 크기가 제약된 구체화를 사용한 것으로 볼 수 있다.

```요약값 -> 크기가 제약된 구체화 -> 성공시 이것을 활용해 시그니처를 검색하여 맞는 부품 인출.```

다른 방법으로 아래와 같은 방법을 생각할 수 있다.

```요약값 -> 부품의 미리 계산된 시그니처들과 매치하여 요약값에 포함되는 상수 추출 (이 상수 갯수의 크기가 제약된) -> 성공시 이 상수들이 포함되어있는 부품 인출```

예를 들어, 1번째 입출력에서 요약값이 [100,199] 구간일때 여기에 맞는 부품을 꺼내려고 한다고 가정하자. 이때 크기가 제약된 구체화만 활용한다면 구체화된 값이 100개이므로 기존의 기본값 8개로 제약된 구체화로는 원하는 상수를 끄집어낼 수 없다. 그러나 현재 보유중인 부품들의 1번째 입출력에 해댱되는 값들이 [100,199] 사이에 120, 140, 160, 180 이렇게 4개 뿐이라면 요약값의 구체화를 전체 적용하는 대신 어차피 부품셋에는 4개의 값밖에 없으므로 이 4개의 값으로 부품을 탐색하면 된다.

현재 이 알고리즘이 구현되어있으나, 아직 성능상의 이득이 크지 않아서 실험적인 옵션으로 남겨둔다.